---
title: Predicting Chemical and Material Molecular Properties With HydraGNN
author: David M. Rogers
tags: ["chemistry", "AI/ML", "tutorial"]
---

The HydraGNN package uses [torch-sparse](https://pypi.org/project/torch-sparse/)
to push data back and forth across the bonds in a molecular graph
until it finally outputs predictions for properties like
electronic energy, heats of formation and light absorption frequencies.

![Molecule graph and HydraGNN Network Topology](/images/hydraGNNtopo.png)
<!-- img src="/images/hydraGNNtopo" width=500 / -->

This article walks through using HydraGNN to
predict the electronic energy of a solid magnesium metal.

## Background

Let's start with some background on AI/ML methods
in computational chemistry.

Computational chemists have actually made use of AI for decades.
However, there's been a flurry of advances recently.
What changed?  The convergence of general GPU-accelerated AI training
packages, large available datasets, and high-performance computing.

Researchers in material and chemical design and discovery at
ORNL have been closely following the flurry of activity in this area:

  - Integrating AI energy functions with LAMMPS MD simulations using [DeePMD](https://docs.deepmodeling.com/projects/deepmd)

  - [Equivariant neural network design](https://arxiv.org/abs/2207.09453) for increased transferrability.

  - [Large datasets](http://quantum-machine.org/datasets/) of
    high-quality molecular (chemical and material)
    structures, along with computed and measured properties.

As a leader in high-performance computing for open science,
some of the unique contributions ORNL has made include:

  - Quantum-mechanical calculations [generating large materials datasets](https://www.nature.com/articles/s41597-021-00812-2).

  - High-accuracy [Quantum Monte-Carlo](https://www.qmcpack.org/) and [Green's-Function Based](https://github.com/CompFUSE/DCA)
    Calculations of Electronic Structure

  - Distributed-parallel dataset loading and training with multiple AI network architectures -- [HydraGNN](https://www.ornl.gov/research-highlight/hydragnn-distributed-pytorch-implementation-multi-headed-graph-convolutional).

<!--
<img src="/images/yakl_yak.webp" width=300 /> -->

## How does AI/ML apply to molecules?

Like most AI methods, the trick to understanding how AI applies
to chemicals is to explain three things:

1. encoding: How does a molecular structure get turned into a vector of inputs?

2. outputs:

  - What outputs are we predicting? 
  - How are they encoded into a vector? 
  - How do we score the AI's outputs (loss function)? 

3. layer topology: What function maps the encoding to
   intermediate layers, and eventually, to the outputs?

For the case of molecules, there are two major paradigms
-- the SMILES string "language" model, and the molecular
graph model.  In the SMILES model, the molecule is represented
by a string (called
the SMILES string), with tokens for atoms, along with special tokens
for functional groups, bonds, etc.  Language models can be applied 
to this representation.  HydraGNN doesn't specialize in the
"language model".

Instead, HydraGNN works with the molecular graph model.
In a molecular graph, atoms are vertices, and bonds form the
edges between them.  However, bonds and atoms don't have to
exactly translate.  We could, for example, add an aromatic center
as a vertex, or add an edge between two nearby atoms to
better model their tendency to push each other away at close distances.

The input, then, is a vector of data associated with each atom
and bond.  This typically includes at least the atomic number.
It may also include atom positions or other relevant data.

The output is usually a vector of properties for the
whole molecule (like total energy), and might also have
properties on each atom or bond (like partial charge
or bond order).

The function used comes from more general ideas about
graph neural networks.  Each node gathers data
from all of its neighbors, and a regular AI/ML network
layer is applied to those inputs.  Typically
the result is summed over all neighbors (incoming edges).

Some common variations on this include, 1) adding geometric
information to incoming edges -- creating the possibility
of rotationally-invariant network outputs.  These "equivariant"
methods usually tap into the [e3nn package](https://github.com/e3nn/e3nn), although
there have been [independent implementations](https://pubs.acs.org/doi/full/10.1021/acs.jctc.3c00214) (https://gitee.com/mindspore/mindscience/tree/master/MindSPONGE)
2) flipping the network by considering the bonds as nodes
and atoms as edges, as in [ChemProp](https://github.com/chemprop/chemprop).  3) using the graph
convolution phase to gather information from local
environments and then performing non-graph updates on
each environment, as in [Allegro](https://github.com/mir-group/allegro).


## Building HydraGNN

We recommend setting up HydraGNN in development mode.
Download a copy, create a virtual environment,
and install the dependencies using pip,

    git clone --branch LoG2023_tutorial https://github.com/ORNL/HydraGNN.git
    pip -m venv .venv
    source .venv/bin/activate

    # To install the latest pytorch version
    # in a way appropriate for your platform,
    # insert instructions from https://pytorch.org here.

    pip install -e .


## Setting up Inputs

### Dataset

We'll use the QM9 dataset.
The original version of QM9 was published in 2014.
It included both 19 graph-level as well as 1 node-level property.
Although QM9 is available through pytorch-geometric's
builtin data loader, that doesn't include atomic partial charges
(the only node-level property).

So, to illustrate HydraGNN predicting all 20 properties
simultaneously (multi-task learning),
we'll download the partial charges and add them
back to pytorch-geometric's pre-processed QM9 dataset.

Pytorch-geometric provides a [nice class](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.QM9.html#torch_geometric.datasets.QM9)
representing the loaded data.

So, we extend that and splice in freshly downloaded data.

Note that the `rdkit` python package is
required to make this work.  It's used for
data pre-processing.  We have to re-do that here
so that the charges are added.

    pip install rdkit

```
class QM9_custom(torch_geometric.datasets.QM9):
    def __init__(self, root: str, var_config=None, pre_filter=None):
        self.graph_feature_names = [
            "mu", "alpha", "HOMO", "LUMO", "del-epi",
            "R2", "ZPVE", "U0", "U", "H",
            "G", "cv", "U0atom", "Uatom", "Hatom",
            "Gatom", "A", "B", "C", ]
        self.graph_feature_dims = [1] * len(self.graph_feature_names)
        self.graph_feature_units = [
            "D", "a_0^3", "eV", "eV", "eV",
            "a_0^2", "eV", "eV", "eV", "eV",
            "eV", "cal/(molK)", "eV", "eV", "eV",
            "eV", "GHz", "GHz", "GHz", ]
        self.node_attribute_names = [
            "atomH", "atomC", "atomN", "atomO", "atomF",
            "atomicnumber", "IsAromatic", "HSP", "HSP2", "HSP3",
            "Hprop", "chargedensity", ]
        self.node_feature_units = [
            "1", "1", "1", "1", "1",
            "1", "1", "1", "1", "1",
            "1", "e", ]
        self.node_feature_dims = [1] * len(
                                self.node_attribute_names)
        self.raw_url_2014 = "https://ndownloader.figstatic.com/files/3195389"
        self.raw_url2 = "https://ndownloader.figshare.com/files/3195404"
        self.var_config = var_config

        super().__init__(root,
                pre_transform=self.qm9_pre_transform,
                pre_filter=pre_filter)

    def download(self):
        # download the external dataset (tarball containing one
        #  xyz file per molecule)
        file_path = download_url(self.raw_url_2014, self.raw_dir)
        os.rename(file_path, os.path.join(self.raw_dir, "dsgdb9nsd.xyz.tar.bz2"))
        extract_tar(
            os.path.join(self.raw_dir, "dsgdb9nsd.xyz.tar.bz2"), self.raw_dir, "r:bz2"
        )
        os.unlink(os.path.join(self.raw_dir, "dsgdb9nsd.xyz.tar.bz2"))

        # 2 more parts of the data:
        file_path = download_url(self.raw_url, self.raw_dir)
        extract_zip(file_path, self.raw_dir)
        os.unlink(file_path)

        file_path = download_url(self.raw_url2, self.raw_dir)
        os.rename(
            os.path.join(self.raw_dir, "3195404"),
            os.path.join(self.raw_dir, "uncharacterized.txt"),
        )

    def qm9_pre_transform(self, data):
        # called to update each sample during load
        self.get_charge(data)
        # re-organize data values to match hydragnn's
        # json config file
        hydragnn.preprocess.update_predicted_values(
            self.var_config["type"],
            self.var_config["output_index"],
            self.graph_feature_dims,
            self.node_feature_dims,
            data,
        )
        hydragnn.preprocess.update_atom_features(
            self.var_config["input_node_features"], data
        )
        return data

    def get_charge(self, data):
        # add charges to a molecule's data record
        # <parse self.raw_dir/"sgdb9nsd_{data.idx+1}.xyz"
        # to a list of 1 charge per atom>
        charge = torch.tensor(charge, dtype=torch.float).view(-1,1)
        data.x = torch.cat((data.x, charge), 1)

# read the json config file
with open("qm9_all20.json", "r") as f:
    config = json.load(f)
var_config = config["NeuralNetwork"]["Variables_of_interest"]

# Instantiate the QM9_custom class, selecting every other
# sample for training.
train = QM9_custom(
            root=os.path.join(os.path.dirname(__file__), "dataset/all20/train"),
            var_config=var_config,
            # train on even samples
            pre_filter=lambda d: data.idx % 2 == 0
          )
```

Similar to the training dataset, the example code
defines validation and test datasets.  These all come
from the same database, but use different `pre_filter` functions
to select out indices from each subset.

```
train_loader, val_loader, test_loader = hydragnn.preprocess.create_dataloaders(
    train, val, test, config["NeuralNetwork"]["Training"]["batch_size"]
)
config = hydragnn.utils.update_config(config, train_loader, val_loader, test_loader)
```

### Network Architecture (model)

This is the easy part.  HydraGNN contains many types of message
passing networks.  These can be selected and configured (number
of layers, layer sizes, etc.) using the json configuration file.

So, the only code needed to setup the model is,

```
model = hydragnn.models.create_model_config(
    config=config["NeuralNetwork"],
    verbosity=config["Verbosity"]["level"],
)
model = hydragnn.utils.get_distributed_model(
                model, config["Verbosity"]["level"])

...

hydragnn.utils.save_model(model, optimizer, log_name)
# reload later:
# model = hydragnn.utils.model.load_existing_model(model, log_name)
```

The neural network architecture used here is specified
by this section of the json file:

```
    "NeuralNetwork": {
        "Architecture": {
            "model_type": "PNA",
            "hidden_dim": 30,
            "num_conv_layers": 6,
            "output_heads": {
                "graph":{
                    "num_sharedlayers": 2,
                    "dim_sharedlayers": 50,
                    "num_headlayers": 2,
                    "dim_headlayers": [50,25]
                },
                "node": {
                    "num_headlayers": 3,
                    "dim_headlayers": [50,50,25],
                    "type": "mlp"
                }
            },
            "task_weights": [1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]
        },
    ...
    }
```

This requests the `PNA` model for graph convolutions,
which have 30 numbers per atom, and run 6 layers.
Graph-level properties pool from all atoms, run 2 shared
layers of dimension 50, then split into separate networks.
Those separate networks have hidden dimensions 50 and 25.

There is just one node-level property, so shared layers
are just as good as individual output heads here.


## Running HydraGNN
 
The data and model created above are the two main ingredients
for running training and inference.  However, the full example
source code (`examples/qm9/qm9_custom.py`) also sets up the
optimizer, a logfile, and does some output plotting after
completing the training.

Note that, in the example above, outputs are scaled to
the min/max observed values across all data, and molecule energies
are divided by the number of atoms.
We have left those scaling steps out of the
walkthrough for simplicity.
 
```
world_size, world_rank = hydragnn.utils.setup_ddp()

# run main training loop
hydragnn.train.train_validate_test(
    model,
    optimizer,
    train_loader,
    val_loader,
    test_loader,
    writer,
    scheduler,
    config["NeuralNetwork"],
    log_name,
    verbosity,
    create_plots=config["Visualization"]["create_plots"],
)
```


## Plotting Outputs

The `plot_predictions_all20` function from the example
plots the prediction losses as a function of training epoch.
It also shows a comparison of true and predicted energies.

The final step is running the forward process and
comparing the input "true" values with the model's predictions.

```
# Use the trained model to predict the values of the training dataset.
_, _, true_values, predicted_values \
        = hydragnn.train.test(dataset_loader, model, 1)
```

![Predicted vs Reference Molecular Properties](/images/hydraGNNqm9.png)

The `qm9_util.py` script creates several types of plots
by looping over data points (molecules),

```
for ihead in range(model.num_heads):
    head_true = true_values[ihead]
    head_pred = predicted_values[ihead]
    unit = var_config["output_units"][ihead]
    varname = var_config["output_names"][ihead]
```

The tensor sizes for values are `(number of molecules, 1)`
for molecular properties and `(summed number of atoms, 1)`
for atomic (node-level) properties.

It's easy to make a scatterplot at this point by transferring
to cpu and calling matplotlib.

```
head_true = head_true.cpu().numpy()
head_pred = head_pred.cpu().numpy()
ax.scatter(head_true, head_pred)
```

## More information
 
For full code examples, tutorials, and usage instructions, see the recent
[Tutorial at LoG2023](https://github.com/ORNL/HydraGNN/blob/LoG2023_tutorial/README.md)
and citation:
 
"HydraGNN: Distributed PyTorch implementation of multi-headed graph convolutional neural networks",
Copyright ID#: 81929619 https://doi.org/10.11578/dc.20211019.2
 
## Author Bios
