---
title: Predicting Chemical and Material Molecular Properties With HydraGNN
author: Pei Zhang, Jong Youl Choi, David M. Rogers, and Max Lupo Pasini
tags: ["chemistry", "AI/ML", "tutorial"]
---

The HydraGNN package uses [torch-sparse](https://pypi.org/project/torch-sparse/)
to push data back and forth across the bonds in a molecular graph
until it finally outputs predictions for properties like
electronic energy, heats of formation and light absorption frequencies.

![Molecule graph and HydraGNN Network Topology](/images/hydraGNNtopo.png)
<!-- img src="/images/hydraGNNtopo" width=500 / -->

This article walks through using HydraGNN to
predict the energies, band gaps, and partial charges of
small molecules including H, C, N O, and F atoms
from the [QM9 dataset](http://quantum-machine.org/datasets/).


## Background

Let's start with some background on AI/ML methods
in computational chemistry.

Computational chemists have actually made use of AI for decades.
However, there's been a flurry of advances recently.
What changed?  The convergence of general GPU-accelerated AI training
packages, large available datasets, and high-performance computing.

Researchers in material and chemical design and discovery at
ORNL have been closely following the flurry of activity in this area:

  - Integrating AI energy functions with LAMMPS MD simulations using [DeePMD](https://docs.deepmodeling.com/projects/deepmd)

  - [Equivariant neural network design](https://arxiv.org/abs/2207.09453) for increased transferrability.

  - [Large datasets](http://quantum-machine.org/datasets/) of
    high-quality molecular (chemical and material)
    structures, along with computed and measured properties.

As a leader in high-performance computing for open science,
some of the unique contributions ORNL has made include:

  - Quantum-mechanical calculations [generating large materials datasets](https://www.nature.com/articles/s41597-021-00812-2).

  - High-accuracy [Quantum Monte-Carlo](https://www.qmcpack.org/) and [Green's-Function Based](https://github.com/CompFUSE/DCA)
    Calculations of Electronic Structure

  - Distributed-parallel dataset loading and training with multiple AI network architectures -- [HydraGNN](https://www.ornl.gov/research-highlight/hydragnn-distributed-pytorch-implementation-multi-headed-graph-convolutional).

## How does AI/ML apply to molecules?

Like most AI methods, the trick to understanding how AI applies
to chemicals is to explain three things:

1. encoding: How does a molecular structure get turned into a vector of inputs?

2. outputs:

  - What outputs are we predicting? 
  - How are they encoded into a vector? 
  - How do we score the AI's outputs (loss function)? 

3. layer topology: What function maps the encoding to
   intermediate layers, and eventually, to the outputs?

For the case of molecules, there are two major paradigms
-- the SMILES string "language" model, and the molecular
graph model.  In the SMILES model, the molecule is represented
by a string (called
the SMILES string), with tokens for atoms, along with special tokens
for functional groups, bonds, etc.  Language models can be applied 
to this representation.  HydraGNN doesn't specialize in the
"language model".

Instead, HydraGNN works with the molecular graph model.
In a molecular graph, atoms are vertices, and bonds form the
edges between them.  However, bonds and atoms don't have to
exactly translate.  We could, for example, add an aromatic center
as a vertex, or add an edge between two nearby atoms to
better model their tendency to push each other away at close distances.

The input, then, is a vector of data associated with each atom
and bond.  This typically includes at least the atomic number.
It may also include atom positions or other relevant data.

The output is usually a vector of properties for the
whole molecule (like total energy), and might also have
properties on each atom or bond (like partial charge
or bond order).

The function used comes from more general ideas about
graph neural networks.  Each node gathers data
from all of its neighbors, and a regular AI/ML network
layer is applied to those inputs.  Typically
the result is summed over all neighbors (incoming edges).

Some common variations on this include, 1) adding geometric
information to incoming edges -- creating the possibility
of rotationally-invariant network outputs.  These "equivariant"
methods usually tap into the [e3nn package](https://github.com/e3nn/e3nn), although
there have been [independent implementations](https://pubs.acs.org/doi/full/10.1021/acs.jctc.3c00214) (https://gitee.com/mindspore/mindscience/tree/master/MindSPONGE)
2) flipping the network by considering the bonds as nodes
and atoms as edges, as in [ChemProp](https://github.com/chemprop/chemprop).  3) using the graph
convolution phase to gather information from local
environments and then performing non-graph updates on
each environment, as in [Allegro](https://github.com/mir-group/allegro).


## Building HydraGNN

We recommend setting up HydraGNN in development mode.
Download a copy, create a virtual environment,
and install the dependencies using pip,

    git clone --branch LoG2023_tutorial https://github.com/ORNL/HydraGNN.git
    pip -m venv .venv
    source .venv/bin/activate

    # To install the latest pytorch version
    # in a way appropriate for your platform,
    # insert instructions from https://pytorch.org here.

    pip install -e .


## Setting up Inputs

### Dataset

We'll use the QM9 dataset.
The original version of QM9 was published in 2014.
It included both 19 graph-level as well as 1 node-level property.
Although QM9 is available through pytorch-geometric's
builtin data loader, that doesn't include atomic partial charges
(the only node-level property).

So, to illustrate HydraGNN predicting all 20 properties
simultaneously (multi-task learning),
we'll download the partial charges and add them
back to pytorch-geometric's pre-processed QM9 dataset.

Pytorch-geometric provides a [nice class](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.QM9.html#torch_geometric.datasets.QM9)
representing the loaded data.

So, we extend that by downloading the
original dataset, parsing the charge column from
each molecule's xyz file, and using `torch.cat((data.x, charge), 1)`
to concatenate the vector of charges to the vector
of properties already provided for the molecule.

Note that the `rdkit` python package is
required to make this work.  It's used for
data pre-processing.  We have to re-do that here
so that the charges are added.

    pip install rdkit

```
class QM9_custom(torch_geometric.datasets.QM9):
    def __init__(self, root: str, var_config=None, pre_filter=None):
        self.graph_feature_names = [
            "mu", "alpha", "HOMO", "LUMO", "del-epi",
            "R2", "ZPVE", "U0", "U", "H",
            "G", "cv", "U0atom", "Uatom", "Hatom",
            "Gatom", "A", "B", "C", ]
        self.graph_feature_dims = [1] * len(self.graph_feature_names)
        self.graph_feature_units = [
            "D", "a_0^3", "eV", "eV", "eV",
            "a_0^2", "eV", "eV", "eV", "eV",
            "eV", "cal/(molK)", "eV", "eV", "eV",
            "eV", "GHz", "GHz", "GHz", ]
        self.node_attribute_names = [
            "atomH", "atomC", "atomN", "atomO", "atomF",
            "atomicnumber", "IsAromatic", "HSP", "HSP2", "HSP3",
            "Hprop", "chargedensity", ]
        self.node_feature_units = [
            "1", "1", "1", "1", "1",
            "1", "1", "1", "1", "1",
            "1", "e", ]
        self.node_feature_dims = [1] * len(
                                self.node_attribute_names)
        self.raw_url_2014 = "https://ndownloader.figstatic.com/files/3195389"
        self.raw_url2 = "https://ndownloader.figshare.com/files/3195404"
        self.var_config = var_config

        try:
            # Fails when re-reading data, since qm9_pre_transform stores
            # just processed data, not pre_filter or pre_transform.
            super().__init__(root,
                    pre_transform=self.qm9_pre_transform,
                    pre_filter=pre_filter)
        except:
            assert os.path.exists(
                os.path.join(self.processed_dir, self.processed_file_names)
            )
            super().__init__(root,
                    pre_transform=self.qm9_pre_transform,
                    pre_filter=pre_filter)

    def download(self):
        # download the external dataset (tarball containing one
        #  xyz file per molecule)
        file_path = download_url(self.raw_url_2014, self.raw_dir)
        os.rename(file_path, os.path.join(self.raw_dir, "dsgdb9nsd.xyz.tar.bz2"))
        extract_tar(
            os.path.join(self.raw_dir, "dsgdb9nsd.xyz.tar.bz2"), self.raw_dir, "r:bz2"
        )
        os.unlink(os.path.join(self.raw_dir, "dsgdb9nsd.xyz.tar.bz2"))

        # 2 more parts of the data:
        file_path = download_url(self.raw_url, self.raw_dir)
        extract_zip(file_path, self.raw_dir)
        os.unlink(file_path)

        file_path = download_url(self.raw_url2, self.raw_dir)
        os.rename(
            os.path.join(self.raw_dir, "3195404"),
            os.path.join(self.raw_dir, "uncharacterized.txt"),
        )

    def qm9_pre_transform(self, data):
        # called to update each sample during load
        self.get_charge(data)
        # re-organize data values to match hydragnn's
        # json config file
        hydragnn.preprocess.update_predicted_values(
            self.var_config["type"],
            self.var_config["output_index"],
            self.graph_feature_dims,
            self.node_feature_dims,
            data,
        )
        hydragnn.preprocess.update_atom_features(
            self.var_config["input_node_features"], data
        )
        return data

    def get_charge(self, data):
        # add charges to a molecule's data record
        # <parse self.raw_dir/"sgdb9nsd_{data.idx+1}.xyz"
        # to a list of 1 charge per atom>
        charge = torch.tensor(charge, dtype=torch.float).view(-1,1)
        data.x = torch.cat((data.x, charge), 1)

# read the json config file
with open("qm9_all20.json", "r") as f:
    config = json.load(f)
var_config = config["NeuralNetwork"]["Variables_of_interest"]

# Instantiate the QM9_custom class, selecting every other
# sample for training.
train = QM9_custom(
            root=os.path.join(os.path.dirname(__file__), "dataset/all20/train"),
            var_config=var_config,
            # train on even samples
            pre_filter=lambda d: data.idx % 2 == 0
          )
```

Similar to the training dataset, the example code
defines validation and test datasets.  These all come
from the same database, but use different `pre_filter` functions
to select out indices from each subset.

Note that QM9 is relatively small, so the entire dataset
is stored in memory.  For larger datasets, HydraGNN provides
different mechanisms for storing and reading back the
pre-transformed data that can take advantage of parallelism.

```
train_loader, val_loader, test_loader = hydragnn.preprocess.create_dataloaders(
    train, val, test, config["NeuralNetwork"]["Training"]["batch_size"]
)
config = hydragnn.utils.update_config(config, train_loader, val_loader, test_loader)
```

The second line above updates the configuration data
to include information (names and data types) about
other features that were found during dataset loading.
It's also intended to store information about how features
were scaled or standardized during loading.


### Network Architecture (model)

This is the easy part.  HydraGNN contains many types of message
passing networks.  These can be selected and configured (number
of layers, layer sizes, etc.) using the json configuration file.

So, the only code needed to setup the model is,

```
model = hydragnn.models.create_model_config(
    config=config["NeuralNetwork"],
    verbosity=config["Verbosity"]["level"],
)
model = hydragnn.utils.get_distributed_model(
                model, config["Verbosity"]["level"])

...

hydragnn.utils.save_model(model, optimizer, log_name)
# reload later:
# model = hydragnn.utils.model.load_existing_model(model, log_name)
```

The call to `get_distributed_model` applies a
distributed data parallel (DDP) wrapper around the model.
Now, calls to methods within `model` will utilize DDP.

The neural network architecture used here is specified
by this section of the json file:

```
    "NeuralNetwork": {
        "Architecture": {
            "model_type": "PNA",
            "hidden_dim": 30,
            "num_conv_layers": 6,
            "output_heads": {
                "graph":{
                    "num_sharedlayers": 2,
                    "dim_sharedlayers": 50,
                    "num_headlayers": 2,
                    "dim_headlayers": [50,25]
                },
                "node": {
                    "num_headlayers": 3,
                    "dim_headlayers": [50,50,25],
                    "type": "mlp"
                }
            },
            "task_weights": [1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]
        },
        "Variables_of_interest": {
            "input_node_features": [0,1,2,3,4,5,6,7,8,9,10],
            "output_index": [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,11],
            "type": ["graph","graph","graph","graph","graph","graph","graph","graph","graph","graph","graph","graph","graph","graph","graph","graph","graph","graph","graph","node"]
        },
    ...
    }
```

This requests the `PNA` model for graph convolutions,
which have 30 numbers per atom, and run 6 layers.
Graph-level properties pool from all atoms, run 2 shared
layers of dimension 50, then split into separate networks.
Those separate networks have hidden dimensions 50 and 25.

There is just one node-level property, so shared layers
are just as good as individual output heads here.

The `Variables_of_interest` specify the input and output
features we are using.  Note that the graph-level and
node-level features are numbered separately, so the
charge is found as the 12-th node-level feature, `("node",11)`.


## Running HydraGNN
 
The data and model created above are the two main ingredients
for running training and inference.  However, the full example
source code (`examples/qm9/qm9_custom.py`) also sets up the
optimizer, a logfile, and does some output plotting after
completing the training.

Note that, in the example above, outputs are scaled to
the min/max observed values across all data, and molecule energies
are divided by the number of atoms.
We have left those scaling steps out of the
walkthrough for simplicity.
 
```
world_size, world_rank = hydragnn.utils.setup_ddp()

# run main training loop
hydragnn.train.train_validate_test(
    model,
    optimizer,
    train_loader,
    val_loader,
    test_loader,
    writer,
    scheduler,
    config["NeuralNetwork"],
    log_name,
    verbosity,
    create_plots=config["Visualization"]["create_plots"],
)
```

Exectuting the `qm9_custom20.py` script at the terminal
will download the dataset, perform pre-processing,
store the pre-processed result inside `dataset/all20`,
and write out logfiles to the `logs/qm9_LOG2023_all20_1113`
subdirectory.


## Plotting Outputs

The `plot_predictions_all20` function from the example
plots the prediction losses as a function of training epoch.
It also shows a comparison of true and predicted energies.

The final step is running the forward process and
comparing the input "true" values with the model's predictions.

```
# Use the trained model to predict the values of the training dataset.
_, _, true_values, predicted_values \
        = hydragnn.train.test(dataset_loader, model, 1)
```

![Predicted vs Reference Molecular Properties](/images/hydraGNNqm9.png)

The `qm9_util.py` script creates several types of plots
by looping over data points (molecules),

```
for ihead in range(model.num_heads):
    head_true = true_values[ihead]
    head_pred = predicted_values[ihead]
    unit = var_config["output_units"][ihead]
    varname = var_config["output_names"][ihead]
```

The tensor sizes for values are `(number of molecules, 1)`
for molecular properties and `(summed number of atoms, 1)`
for atomic (node-level) properties.

It's easy to make a scatterplot at this point by transferring
to cpu and calling matplotlib.

```
head_true = head_true.cpu().numpy()
head_pred = head_pred.cpu().numpy()
ax.scatter(head_true, head_pred)
```

In the plot shown here, all 20 outputs show a good
amount of predictive power, even with such a short
training time and small network.
The last one is `charge`, the only node-level property
for this example.

## More information
 
For full code examples, tutorials, and usage instructions, see the recent
[Tutorial at LoG2023](https://github.com/ORNL/HydraGNN/blob/LoG2023_tutorial/README.md), and [associated presentation slides](https://drive.google.com/drive/folders/1RPDVLMbWj-_EydnuxysTu3AKEuEw9xxI).

A video presentation of this walkthrough is
[available on youtube](https://youtu.be/U5oHXGcHBdk?t=6153).

Please cite HydraGNN by referencing the following:
"HydraGNN: Distributed PyTorch implementation of multi-headed graph convolutional neural networks",
Copyright ID#: 81929619 https://doi.org/10.11578/dc.20211019.2
 
# Authors

[Pei Zhang](https://www.ornl.gov/staff-profile/pei-zhang)
is a Computational Scientist in the Multiscale Materials group,
where she uses data-driven and physics-based modeling approaches
to solve multiscale multiphysics problems - like
graph neural networks (GNNs) and large language models
(LLMs) for molecular properties, efficient
reinforcement learning (RL) algorithm development, and
dimension reduction for stiff chemical dynamic systems.
She obtained her PhD in Aerospace Engineering
from Purdue University on the topic of turbulent combustion modeling
using large eddy simulation (LES) and transported
probability density function (TPDF) methods. 

[Jong Youl Choi](http://csed.ornl.gov/profile/jong-youl-choi)
is a Research Scientist in the Discrete Algorithms group,
where he uses data mining and machine learning algorithms, high-performance data-intensive computing, parallel and distributed systems to
research and develop data-centric machine learning algorithms
for large scale data management, in situ/in-transit data processing,
and data management for code coupling.
He earned his Ph.D. degree in Computer Science at
Indiana University Bloomington.

[David M. Rogers](https://www.olcf.ornl.gov/directory/staff-member/david-rogers/)
is a Computational Scientist in the Advanced Computing for Chemistry and Materials group, where he works to develop mathematical and computational theory jointly with methods for multiscale modeling using HPC. He obtained his Ph.D. in Physical Chemistry from University of Cincinnati in 2009 on the topic
of applying Bayes' theorem to the free energy problem with applications to multiscale modeling of fluids and interface chemistry.


[Max Lupo-Pasini](https://www.ornl.gov/staff-profile/massimiliano-lupo-pasini)
is a Data Scientist in the Computational Coupled Physics
group, where he develops surrogate and generative AI models for material sciences, scalable hyper parameter optimization techniques for deep learning (DL) models, and acceleration of computational methods for physics applications.
He obtained his PhD in Applied Mathematics at Emory University in Atlanta (GA)
on the development of efficient and resilient linear solvers for upcoming
computing architectures moving towards exascale.
